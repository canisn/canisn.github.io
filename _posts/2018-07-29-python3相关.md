---
layout: post
title:  "Python3相关"
categories:  python 
tags:  多线程 多进程
author: canisn
---

* content
{:toc}




# 1.多线程与多进程
由于进程锁的原因，在python中多线程也无法使用多核CPU的优势，而multiprocessing提供了解决方案。

```python
# 查看机器物理CPU数量
import os
n = os.cpu_count()
```
## 1.1类原形
multiprocessing启用多进程，支持子进程、通信和共享数据、执行不同形式的同步，提供了Process、Queue、Pipe、Lock等组件。注意进程直接是独立的，不共享任何状态和变量。


```python
Process([group [, target [, name [, args [, kwargs]]]]])，由该类实例化得到的对象，表示一个子进程中的任务（尚未启动）
# args指定的为传给target函数的位置参数，是一个元组形式，必须有逗号
```
### 相关方法
```python
p.start()：启动进程，并调用该子进程中的p.run() 
p.run():进程启动时运行的方法，正是它去调用target指定的函数，我们自定义类的类中一定要实现该方法  

p.terminate():强制终止进程p，不会进行任何清理操作，如果p创建了子进程，该子进程就成了僵尸进程，使用该方法需要特别小心这种情况。如果p还保存了一个锁那么也将不会被释放，进而导致死锁
p.is_alive():如果p仍然运行，返回True

p.join([timeout]):主线程等待p终止（强调：是主线程处于等的状态，而p是处于运行的状态）。timeout是可选的超时时间，需要强调的是，p.join只能join住start开启的进程，而不
能join住run开启的进程  

```
### 相关属性

```python
p.daemon：默认值为False，如果设为True，代表p为后台运行的守护进程，当p的父进程终止时，p也随之终止，并且设定为True后，p不能创建自己的新进程，必须在p.start()之前设置

p.name:进程的名称

p.pid：进程的pid

p.exitcode:进程在运行时为None、如果为–N，表示被信号N结束(了解即可)

p.authkey:进程的身份验证键,默认是由os.urandom()随机生成的32字符的字符串。这个键的用途是为涉及网络连接的底层进程间通信提供安全性，这类连接只有在具有相同的身份验证键时才
能成功（了解即可）
```
## 1.2多进程启用实例--进程池

```python
import time
import random
import multiprocessing

def fn(name):
	print("peocess %s start!" % name)
	time.sleep(random.randrange(10))
	print("peocess %s stop!" % name)

proc_poll = multiprocessing.Pool(6)

for i in range(3):
    proc_poll.apply_async(fn, args=("%s" % i,))

proc_poll.close()
proc_poll.join()

print("main process")
------
peocess 0 start!
peocess 0 stop!
peocess 1 start!
peocess 1 stop!
peocess 2 start!
peocess 2 stop!
main process
```
## 1.3继承方法启用实例

```
class Fn(Process):
	def __init__(self, name):
		super().__init__()
		self.name = name

	def run(self):
		print("peocess %s start!" % self.name)
		time.sleep(random.randrange(10))
		print("peocess %s stop!" % self.name)

for i in range(3):
    # 实例化进程
	p = Fn("%s" % i)
	# 启动实例，自动调用run函数
	p.start() 

print("main process")
```
## 1.4僵尸进程和孤儿进程

### 1.4.1 僵尸进程：对系统有害

在linux/unix中，父进程与子进程是并行状态，如果子进程先结束了，而父进程没有结束，为了保证父进程能够获取子进程的状态，子进程在退出后依然会保持基本的数据结构，包含进程号the process ID，退出状态the termination status of the process，运行时间the amount of CPU time taken by the process等，系统的进程号有限，如果没有回收将耗尽！

父进程通过wait / waitpid来取时才释放子进程的遗留数据结构，如果没有这个步骤，就永远僵尸了。

### 1.4.2. 孤儿进程：无害

孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

　　孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上，init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤 儿进程的父进程设置为init，而init进程会循环地wait()它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。因此孤儿进程并不会有什么危害。

## 1.5守护进程

主进程创建守护进程

其一：守护进程会在主进程代码执行结束后就终止

其二：守护进程内无法再开启子进程,否则抛出异常：AssertionError: daemonic processes are not allowed to have children

注意：进程之间是互相独立的，主进程代码运行结束，守护进程随即终止

```python
p=Fn('aaa')
#一定要在p.start()前设置,设置p为守护进程,禁止p创建子进程,并且父进程代码执行结束,p即终止运行
p.daemon=True 
p.start()
```

## 1.6进程锁
进程之间数据不共享,但是共享同一套文件系统,所以访问同一个文件,或同一个打印终端,是没有问题的,

而共享带来的是竞争，竞争带来的结果就是错乱，如何控制，就是加锁处理


```python
from multiprocessing import Process,Lock
import os,time
def work(lock):
    lock.acquire()
    print('%s is running' %os.getpid())
    time.sleep(2)
    print('%s is done' %os.getpid())
    lock.release()
if __name__ == '__main__':
    lock=Lock()
    for i in range(3):
        p=Process(target=work,args=(lock,))
        p.start()
-----
40279 is running
40279 is done
40280 is running
40280 is done
40281 is running
40281 is done
[Finished in 6.1s]
```
## 1.7信号量
信号量与进程锁很类似，但是信号量允许一次又一定数量的操作者。

```python
from multiprocessing import Process,Semaphore
import time,random

def go_wc(sem,user):
    sem.acquire()
    print('%s get one hole' %user)
    time.sleep(random.randint(0,3))
    sem.release()

if __name__ == '__main__':
    sem=Semaphore(5)
    p_l=[]
    for i in range(13):
        p=Process(target=go_wc,args=(sem,'user%s' %i,))
        p.start()
        p_l.append(p)

    for i in p_l:
        i.join()
    print('main done')
```



## 1.8队列和管道

1 队列和管道都是将数据存放于内存中

2 队列又是基于（管道+锁）实现的，可以让我们从复杂的锁问题中解脱出来，
我们应该尽量避免使用共享数据，尽可能使用消息传递和队列，避免处理复杂的同步和锁问题，而且在进程数目增多时，往往可以获得更好的可获展性。

## 1.9进程间的通信-队列

```python
from multiprocessing import Process,Queue
import time
q=Queue(3)
#put ,get ,put_nowait,get_nowait,full,empty
q.put(3)
q.put(3)
q.put(3)
print(q.full()) #满了

print(q.get())
print(q.get())
print(q.get())
print(q.empty()) #空了
```

队列还有一个好处就是可以用于处理多生产者多消费者问题

JoinableQueue([maxsize])：这就像是一个Queue对象，但队列允许项目的使用者通知生成者项目已经被成功处理。通知进程是使用共享的信号和条件变量来实现的。

#参数介绍：
maxsize是队列中允许最大项数，省略则无大小限制。    
#方法介绍：
JoinableQueue的实例p除了与Queue对象相同的方法之外还具有：

q.task_done()：使用者使用此方法发出信号，表示q.get()的返回项目已经被处理。如果调用此方法的次数大于从队列中删除项目的数量，将引发ValueError异常

q.join():生产者调用此方法进行阻塞，直到队列中所有的项目均被处理。阻塞将持续到队列中的每个项目均调用q.task_done（）方法为止


```python
from multiprocessing import Process,JoinableQueue
import time,random,os
def consumer(q):
    while True:
        res=q.get()
        time.sleep(random.randint(1,3))
        print('%s consumer %s' %(os.getpid(),res))

        q.task_done() #向q.join()发送一次信号,证明一个数据已经被取走了

def producer(name,q):
    for i in range(3):
        time.sleep(random.randint(1,3))
        res="name:%s, i:%s" %(name,i)
        q.put(res)
        print('%s produce %s' %(os.getpid(),res))
    q.join()


if __name__ == '__main__':
    q=JoinableQueue()
    #生产者们:即厨师们
    p1=Process(target=producer,args=('aa',q))
    p2=Process(target=producer,args=('bb',q))
    p3=Process(target=producer,args=('cc',q))

    #消费者们:即吃货们
    c1=Process(target=consumer,args=(q,))
    c2=Process(target=consumer,args=(q,))
    c1.daemon=True
    c2.daemon=True

    #开始
    p_l=[p1,p2,p3,c1,c2]
    for p in p_l:
        p.start()

    p1.join()
    p2.join()
    p3.join()
    print("main") 
```

